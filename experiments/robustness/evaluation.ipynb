{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a408c100",
   "metadata": {},
   "source": [
    "### Evaluation of the robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from matplotlib.text import TextPath\n",
    "from matplotlib.font_manager import FontProperties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8760415",
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparations\n",
    "df = pd.read_csv(\"./robustness.csv\")\n",
    "\n",
    "### optional penalize all entries where a method has a -1.0 in pvalue, i.e., it failed computing, setting\n",
    "### pvalue as it did not match the appropriate decision e.g., see below\n",
    "# CI test decisions, i.e., \n",
    "# reject H_0 for pvalue <= alpha, i.e., we assume H_1 is true -> edge (1) \n",
    "# cannot reject for pvalue > alpha i.e., we assume H_0 is true -> no edge (0)\n",
    "df['pvalue'] = np.where(((df[\"pvalue\"] == -1.0) & (df['hasedge'] == False)), 0.0, df['pvalue'])\n",
    "df['pvalue'] = np.where(((df[\"pvalue\"] == -1.0) & (df['hasedge'] == True)), 1.0, df['pvalue'])\n",
    "\n",
    "\n",
    "df.loc[df[\"hasedge\"] == False, \"H_0\"] = 0    #H_0 true is 0 (independent, no edge)\n",
    "df.loc[df[\"hasedge\"] == True, \"H_0\"] = 1    #H_0 false is 1 (dependent, edge)\n",
    "\n",
    "# CI test decisions, i.e., \n",
    "# reject H_0 for pvalue <= alpha, i.e., we assume H_1 is true -> edge (1) \n",
    "# cannot reject for pvalue > alpha i.e., we assume H_0 is true -> no edge (0)\n",
    "df[\"CItest\"] = df[\"pvalue\"].le(alpha).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### further preparations and grouping\n",
    "## compute error rate type 1 & type 2 over CGMs grouped by samples, sepsetsize and discretenoderatio\n",
    "def computeTypeI(y, pred):\n",
    "    d = {}\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y, pred, labels=[0, 1]).ravel()\n",
    "    d['error rate'] = (fp / (fp + tn))\n",
    "    d['error type'] = \"type I error\"\n",
    "    return pd.Series(d, index=['error type', 'error rate'])\n",
    "def computeTypeII(y, pred):\n",
    "    d = {}\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y, pred, labels=[0, 1]).ravel()\n",
    "    d['error type'] = \"type II error\"\n",
    "    d['error rate'] = (fn / (tp + fn))\n",
    "    return pd.Series(d, index=['error type', 'error rate'])\n",
    "\n",
    "### we do not group over the cgmid in order to get the error rates for a select setting as a combination of:\n",
    "### (discretenoderatio, sepsetsize, sample) over 100 Experiments (i.e., CGMs)\n",
    "#groupedI = df_1.groupby(['cgmid', 'hasedge', 'samples', 'sepsetsize', 'discretenoderatio']).apply(lambda x: computeTypeI(x[[\"H_0\"]], x[[\"CItest\"]])).reset_index()\n",
    "#groupedII = df_1.groupby(['cgmid', 'hasedge', 'samples', 'sepsetsize', 'discretenoderatio']).apply(lambda x: computeTypeII(x[[\"H_0\"]], x[[\"CItest\"]])).reset_index()\n",
    "groupedI = df.groupby(['samples', 'sepsetsize', 'discretenoderatio']).apply(lambda x: computeTypeI(x[[\"H_0\"]], x[[\"CItest\"]])).reset_index()\n",
    "groupedII = df.groupby(['samples', 'sepsetsize', 'discretenoderatio']).apply(lambda x: computeTypeII(x[[\"H_0\"]], x[[\"CItest\"]])).reset_index()\n",
    "grouped = pd.concat([groupedI, groupedII],ignore_index=True)\n",
    "\n",
    "## renaming columns\n",
    "grouped['$d_Z$'] = grouped['sepsetsize']\n",
    "grouped['dnr'] = grouped['discretenoderatio']\n",
    "grouped['sample sizes $n$'] = grouped['samples']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd889d",
   "metadata": {},
   "source": [
    "### Figure 1 in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73532240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fp = FontProperties( weight=\"bold\")#, size =  14)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=5, sharey=True, figsize=(16, 3.6))\n",
    "\n",
    "subgroup = grouped[grouped.dnr == 0.0]\n",
    "line = subgroup[subgroup['$d_Z$'] == 1]\n",
    "label = TextPath((0,0), str(1), prop = fp)\n",
    "f1 = sns.lineplot(x=\"sample sizes $n$\", y=\"error rate\", hue=\"error type\", palette=\"colorblind\", data=line, marker=label, markersize=19, ax=axs[0])\n",
    "\n",
    "\n",
    "for dz in [3,5,7]:\n",
    "    line = subgroup[subgroup['$d_Z$'] == dz]\n",
    "    label = TextPath((0,0), str(dz), prop = fp)\n",
    "    f1 = sns.lineplot(x=\"sample sizes $n$\", y=\"error rate\", hue=\"error type\", palette=\"colorblind\", data=line, marker=label, markersize=19, ax=axs[0], legend=False)\n",
    "    f1.set_ylabel(\"error rate\")\n",
    "    f1.set_xlabel(\"sample sizes $n$\")\n",
    "    f1.spines[\"top\"].set_visible(False)\n",
    "    f1.spines[\"right\"].set_visible(False)\n",
    "    f1.set_title('dnr=0.0',{'fontsize': 12})\n",
    "    f1.legend([],[], frameon=False)\n",
    "\n",
    "for i,dnr in enumerate([0.25, 0.5, 0.75, 1.0]):\n",
    "    subgroup = grouped[grouped.dnr == dnr]\n",
    "    for dz in [1,3,5,7]:\n",
    "        line = subgroup[subgroup['$d_Z$'] == dz]\n",
    "        label = TextPath((0,0), str(dz), prop = fp)\n",
    "        f2 = sns.lineplot(x=\"sample sizes $n$\", y=\"error rate\", hue=\"error type\", palette=\"colorblind\", data=line, marker=label, markersize=19, ax=axs[i+1], legend=False)\n",
    "        f2.set_ylabel(\"error rate\")\n",
    "        f2.set_xlabel(\"sample sizes $n$\")\n",
    "        f2.spines[\"top\"].set_visible(False)\n",
    "        f2.spines[\"right\"].set_visible(False)\n",
    "        f2.set_title('dnr='+str(dnr),{'fontsize': 12})\n",
    "        f2.legend([],[], frameon=False)\n",
    "\n",
    "\n",
    "f1.legend(loc='upper center', bbox_to_anchor=(2.5, 1.25), frameon=False, ncol=2)\n",
    "fig.savefig('./case_1_combined.pdf',bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe5f05",
   "metadata": {},
   "source": [
    "### Figure A.1. in appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b13682",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create plots\n",
    "g = sns.FacetGrid(grouped, col=\"$d_Z$\", row=\"dnr\",hue=\"error type\", palette=\"colorblind\")\n",
    "g.set(ylim=(0, 1))\n",
    "g.map_dataframe(sns.lineplot, x=\"sample sizes $n$\", y=\"error rate\")\n",
    "g.add_legend(title=\"\",loc='upper center')\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.savefig('./Robusteness_expanded.pdf',bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
