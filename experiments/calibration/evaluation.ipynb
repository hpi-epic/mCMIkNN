{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942ccc5d",
   "metadata": {},
   "source": [
    "### Evaluation of the calibrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83468b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters \n",
    "# define alpha\n",
    "alpha = 0.05\n",
    "# kcmi kperm\n",
    "sum_kcmi = [5,25,100,200]\n",
    "sum_kperm = [5,25,100,200]\n",
    "# auc function\n",
    "def calc_auc(y,pred):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "def calc_typeIrate(y,pred):\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y, pred, labels=[0, 1]).ravel()\n",
    "    return (fp / (fp + tn))\n",
    "\n",
    "def calc_typeIIrate(y,pred):\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y, pred, labels=[0, 1]).ravel()\n",
    "    return (fn / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparation steps\n",
    "# load dataframe\n",
    "df = pd.read_csv('./calibration.csv')\n",
    "# add CItest and H_0\n",
    "df[\"H_0\"] = df[\"hasedge\"].astype(int)\n",
    "df[\"CItest\"] = df[\"pvalue\"].le(alpha).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636bda31",
   "metadata": {},
   "source": [
    "#### Table A.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\\begin{table}[!htb]\")\n",
    "print(\"\\\\caption{ROC AUC for different combinations of $k_{CMI}$, $k_{perm}$, and samples $n$ with fixed $M_{perm}\\\\!=\\\\!1\\\\,000$ derived from CI decisions over multiple settings, e.g., sampled with a varying dimension of $Z$, $d_Z \\in\\{1,3,5,7\\}$, continuous functions, or discrete node ratios (see Table~\\\\ref{tab:app:Calibration:Param}).}\")\n",
    "print(\"\\\\label{tab:supplement:CalibrationAUC}\")\n",
    "\n",
    "print(\"\\\\begin{center}\")\n",
    "print(\"\\\\resizebox{0.9\\\\linewidth}{!}{\")\n",
    "print('\\\\begin{tabular*}{1\\\\columnwidth}{@{\\\\extracolsep{\\\\fill} } c | c', ' '.join('c' for x in range(0,len(sum_kperm))),'}')\n",
    "print(\"\\\\toprule\")\n",
    "print('\\makecell[c]{samples $n$} & \\\\backslashbox{$k_{CMI}$}{$k_{perm}$} &',' & '.join(str(int(x)) for x in sorted(sum_kperm)), ' \\\\\\ ')\n",
    "\n",
    "\n",
    "for samples in sorted(df['samples'].unique()):\n",
    "    # subselect and compute auc\n",
    "    subset = df[(df.samples == samples)]\n",
    "    subset = subset[[\"kperm\", \"kcmi\", \"hasedge\", \"pvalue\", \"H_0\", \"CItest\"]]\n",
    "    grouped = subset.groupby([\"kcmi\",\"kperm\"]).apply(lambda x: calc_auc(x[[\"H_0\"]], x[[\"CItest\"]])).reset_index(name='AUC')\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"\\\\midrule\")\n",
    "    line = \"\\\\multirow{\"+str(sum(sum_kcmi < samples))+\"}{*}{\"+str(samples) + \"} & \"\n",
    "\n",
    "    ## determine highest value for textbf\n",
    "    highest = 0\n",
    "    for y in sorted(sum_kcmi):\n",
    "        if y >= samples:\n",
    "            continue\n",
    "        for x in sorted(sum_kperm):\n",
    "            if x >= samples:\n",
    "                continue\n",
    "            row = grouped[((grouped.kcmi == y) & (grouped.kperm == x))]\n",
    "            highest = round(row.iloc[0]['AUC'],2) if (round(row.iloc[0]['AUC'],2) > highest) else highest    \n",
    "\n",
    "    for y in sorted(sum_kcmi):\n",
    "        if y >= samples:\n",
    "            continue\n",
    "        line += str(int(y))\n",
    "        for x in sorted(sum_kperm):\n",
    "            if x >= samples:\n",
    "                line += \" & - \" \n",
    "            else:\n",
    "                row = grouped[((grouped.kcmi == y) & (grouped.kperm == x))]\n",
    "                line += \" & \" + str(round(row.iloc[0]['AUC'],2)) if (round(row.iloc[0]['AUC'],2) < highest) else \" & \\\\textbf{\" + str(round(row.iloc[0]['AUC'],2)) +\"}\"\n",
    "        line += ' \\\\\\ '\n",
    "        print(line)\n",
    "        line = \" & \"\n",
    "      \n",
    "        \n",
    "print(\"\\\\bottomrule\")\n",
    "print(\"\\\\end{tabular*}\")\n",
    "print(\"}\\\\end{center}\")\n",
    "print(\"\\\\end{table}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8548c47",
   "metadata": {},
   "source": [
    "#### Table A.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\\begin{table}[!htb]\")\n",
    "print(\"\\\\caption{Type I (top) and type II (bottom) error rates for different combinations of $k_{CMI}$, $k_{perm}$, and samples $n$ with fixed $M_{perm}\\\\!=\\\\!1\\\\,000$ derived from CI decisions over multiple settings, e.g., sampled with a varying dimension of $Z$, $d_Z \\\\in\\\\{1,3,5,7\\\\}$, continuous functions, or discrete node ratios (see Table~\\\\ref{tab:app:Calibration:Param}).}\")\n",
    "print(\"\\\\label{tab:supplement:CalibrationTypeI}\")\n",
    "print(\"\\\\begin{center}\")\n",
    "\n",
    "print('\\\\begin{tabular*}{1\\\\columnwidth}{@{\\\\extracolsep{\\\\fill} } c | c', ' '.join('c' for x in range(0,len(sum_kperm))),'}')\n",
    "print(\"\\\\toprule\")\n",
    "print(\"\\\\multicolumn{6}{c}{Type I Error Rates} \\\\\\ \")\n",
    "print(\"\\\\midrule\")\n",
    "print('\\makecell[c]{samples\\\\\\$n$} & \\\\backslashbox{$k_{CMI}$}{$k_{perm}$} &',' & '.join(str(int(x)) for x in sorted(sum_kperm)), ' \\\\\\ ')\n",
    "\n",
    "\n",
    "for samples in sorted(df['samples'].unique()):\n",
    "    # subselect and compute auc\n",
    "    #subset = perm500[(perm500.samples == samples)]\n",
    "    subset = df[(df.samples == samples)]\n",
    "    subset = subset[[\"kperm\", \"kcmi\", \"hasedge\", \"pvalue\", \"H_0\", \"CItest\"]]\n",
    "    grouped = subset.groupby([\"kcmi\",\"kperm\"]).apply(lambda x: calc_typeIrate(x[[\"H_0\"]], x[[\"CItest\"]])).reset_index(name='AUC')\n",
    "    \n",
    "    \n",
    "    print(\"\\\\midrule\")\n",
    "    line = \"\\\\multirow{\"+str(sum(sum_kcmi < samples))+\"}{*}{\"+str(samples) + \"} & \"\n",
    "    \n",
    "    ## determine smallest value for textbf\n",
    "    smallest = 1\n",
    "    for y in sorted(sum_kcmi):\n",
    "        if y >= samples:\n",
    "            continue\n",
    "        for x in sorted(sum_kperm):\n",
    "            if x >= samples:\n",
    "                continue\n",
    "            else:\n",
    "                row = grouped[((grouped.kcmi == y) & (grouped.kperm == x))]\n",
    "                smallest = round(row.iloc[0]['AUC'],2) if (round(row.iloc[0]['AUC'],2) < smallest) else smallest    \n",
    "    \n",
    "    for y in sorted(sum_kcmi):\n",
    "        if y >= samples:\n",
    "            continue\n",
    "        line += str(int(y))\n",
    "        for x in sorted(sum_kperm):\n",
    "            if x >= samples:\n",
    "                line += \" & - \" \n",
    "            else:\n",
    "                row = grouped[((grouped.kcmi == y) & (grouped.kperm == x))]\n",
    "                line += \" & \" + str(round(row.iloc[0]['AUC'],2)) if (round(row.iloc[0]['AUC'],2) > smallest) else \" & \\\\textbf{\" + str(round(row.iloc[0]['AUC'],2)) +\"}\"\n",
    "        line += ' \\\\\\ '\n",
    "        print(line)\n",
    "        line = \" & \"\n",
    "\n",
    "print(\"\\\\midrule\")\n",
    "print(\"\\\\multicolumn{6}{c}{Type II Error Rates} \\\\\\ \")\n",
    "\n",
    "for samples in sorted(df['samples'].unique()):\n",
    "    # subselect and compute auc\n",
    "    subset = df[(df.samples == samples)]\n",
    "    subset = subset[[\"kperm\", \"kcmi\", \"hasedge\", \"pvalue\", \"H_0\", \"CItest\"]]\n",
    "    grouped = subset.groupby([\"kcmi\",\"kperm\"]).apply(lambda x: calc_typeIIrate(x[[\"H_0\"]], x[[\"CItest\"]])).reset_index(name='AUC')\n",
    "\n",
    "    print(\"\\\\midrule\")\n",
    "    line = \"\\\\multirow{\"+str(sum(sum_kcmi < samples))+\"}{*}{\"+str(samples) + \"} & \"\n",
    "    \n",
    "    ## determine smallest value for textbf\n",
    "    smallest = 1\n",
    "    for y in sorted(sum_kcmi):\n",
    "        if y >= samples:\n",
    "            continue\n",
    "        for x in sorted(sum_kperm):\n",
    "            if x >= samples:\n",
    "                continue\n",
    "            else:\n",
    "                row = grouped[((grouped.kcmi == y) & (grouped.kperm == x))]\n",
    "                smallest = round(row.iloc[0]['AUC'],2) if (round(row.iloc[0]['AUC'],2) < smallest) else smallest    \n",
    "    \n",
    "    for y in sorted(sum_kcmi):\n",
    "        if y >= samples:\n",
    "            continue\n",
    "        line += str(int(y))\n",
    "        for x in sorted(sum_kperm):\n",
    "            if x >= samples:\n",
    "                line += \" & - \" \n",
    "            else:\n",
    "                row = grouped[((grouped.kcmi == y) & (grouped.kperm == x))]\n",
    "                line += \" & \" + str(round(row.iloc[0]['AUC'],2)) if (round(row.iloc[0]['AUC'],2) > smallest) else \" & \\\\textbf{\" + str(round(row.iloc[0]['AUC'],2)) +\"}\"\n",
    "        line += ' \\\\\\ '\n",
    "        print(line)\n",
    "        line = \" & \"\n",
    "\n",
    "print(\"\\\\bottomrule\")\n",
    "print(\"\\\\end{tabular*}\")\n",
    "print(\"\\\\end{center}\")\n",
    "print(\"\\\\end{table}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
