{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ab601c",
   "metadata": {},
   "source": [
    "### Execution of mCMIkNN within the context of CSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d340b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "from itertools import combinations, product, chain\n",
    "from math import floor\n",
    "from multiprocessing import Pool, RawArray\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.special import digamma\n",
    "from scipy.stats import rankdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d84f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup folder\n",
    "try:\n",
    "    os.mkdir('./results_mCMIkNN/')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af752063",
   "metadata": {},
   "outputs": [],
   "source": [
    "### manual added implementation of mCMIkNN\n",
    "\n",
    "class IndependenceTest(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def test_params(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_pval(self, x, y, z):\n",
    "        pass\n",
    "    \n",
    "class mCMIkNN(IndependenceTest):\n",
    "    '''\n",
    "        An independence test class that provides acces to the following non-parametric methods described in Huegle et al. (2022)\n",
    "        - compute_mi: non-parametric estimator for mutual information I(X;Y)\n",
    "        - compute_cmi: non-parametric estimator for conditional mutual information I(X;Y|Z)\n",
    "        - compute_pval_mi: non-parametric independence test returning p value for H_0: X _||_ Y\n",
    "        - compute_pval: non-parametric conditional independence test returing p value for H_0: X _||_ Y | Z\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 kcmi=25,\n",
    "                 kperm=5,\n",
    "                 Mperm=100,\n",
    "                 subsample=None,\n",
    "                 transform=None,\n",
    "                 log_warning=False):\n",
    "\n",
    "        # Required parameters with defaults\n",
    "        self.Mperm = Mperm\n",
    "        self.kcmi = kcmi\n",
    "        self.kperm = kperm\n",
    "        # Persisted values\n",
    "        self.cmi_val = None\n",
    "        self.null_distribution = None\n",
    "        self.permutation = None\n",
    "        self.pval = None\n",
    "        # Options\n",
    "        self.transform = transform\n",
    "        self.dis = 10\n",
    "        self.subsample = subsample\n",
    "        self.leafsize = 16\n",
    "        self.log_warning = log_warning\n",
    "\n",
    "    def test_params(self):\n",
    "        return {\n",
    "            'kcmi': self.kcmi,\n",
    "            'kperm':self.kperm,\n",
    "            'Mperm': self.Mperm,\n",
    "            'Transformation': self.transform,\n",
    "        }\n",
    "\n",
    "    def rank_transform(self, x, y, z=None):\n",
    "        '''\n",
    "            Rank Transform all variables while preserving rank of discrete points.\n",
    "        '''\n",
    "        x_transformed = rankdata(x, method='dense', axis=0).astype(np.float32)\n",
    "        y_transformed = rankdata(y, method='dense', axis=0).astype(np.float32)\n",
    "        z_transformed = None if np.all(z) == None else rankdata(z, method='dense', axis=0).astype(np.float32)\n",
    "        return (x_transformed, y_transformed, z_transformed)\n",
    "\n",
    "    def uniform_transform(self, x, y, z=None):\n",
    "        '''\n",
    "            Transform all variables to take values in [0,1] with equal distances while preserving discrete points (i.e., normalized rank transformed variables).\n",
    "        '''\n",
    "        x_transformed = self.normalize(rankdata(x, method='dense', axis=0).astype(np.float32))\n",
    "        y_transformed = self.normalize(rankdata(y, method='dense', axis=0).astype(np.float32))\n",
    "        z_transformed = None if np.all(z) == None else self.normalize(rankdata(z, method='dense', axis=0).astype(np.float32))\n",
    "        return (x_transformed, y_transformed, z_transformed)\n",
    "\n",
    "    def standardize(self, x):\n",
    "        x_mean = np.mean(x, axis=0)\n",
    "        x_std = np.std(x, axis=0)\n",
    "        return (x - x_mean) / x_std\n",
    "\n",
    "    def standard_transform(self, x, y, z=None):\n",
    "        '''\n",
    "            Standardize all continuous variables (unique values > 10) to std. normal distribution,\n",
    "            i.e., (x-mean(x))/std(x)\n",
    "        '''\n",
    "        res = []\n",
    "        # Standardize Xa if unique(Xa) > 10\n",
    "        xN = []\n",
    "        for a in x.T:\n",
    "            if np.unique(a, axis=0).shape[0] > self.dis:\n",
    "                xN.append(self.standardize(a))\n",
    "            else:\n",
    "                xN.append(a)\n",
    "        res.append(np.asarray(xN).T)\n",
    "\n",
    "        # Standardize Ya if unique(Ya) > 10\n",
    "        yN = []\n",
    "        for a in y.T:\n",
    "            if np.unique(a, axis=0).shape[0] > self.dis:\n",
    "                yN.append(self.standardize(a))\n",
    "            else:\n",
    "                yN.append(a)\n",
    "        res.append(np.asarray(yN).T)\n",
    "\n",
    "        # Standardize Za if unique(Za) > 10\n",
    "        zN = []\n",
    "        if np.all(z) != None:\n",
    "            for a in z.T:\n",
    "                if np.unique(a, axis=0).shape[0] > self.dis:\n",
    "                    zN.append(self.standardize(a))\n",
    "                else:\n",
    "                    zN.append(a)\n",
    "            res.append(np.asarray(zN).T)\n",
    "        else:\n",
    "            res.append(None)\n",
    "        return res\n",
    "\n",
    "    def normalize(self, x):\n",
    "        x_min = np.min(x, axis=0)\n",
    "        x_max = np.max(x, axis=0)\n",
    "        return (x-x_min)/(x_max-x_min)\n",
    "\n",
    "    def normal_transform(self, x, y, z=None):\n",
    "        '''\n",
    "            Normalize all continuous variables (unique values > 10) to take values in [0,1],\n",
    "            i.e., (x-min(x))/(max(x)-min(x))\n",
    "        '''\n",
    "        res = []\n",
    "        # Normalize Xa if unique(Xa) > 10\n",
    "        xN = []\n",
    "        for a in x.T:\n",
    "            if np.unique(a, axis=0).shape[0] > self.dis:\n",
    "                xN.append(self.normalize(a))\n",
    "            else:\n",
    "                xN.append(a)\n",
    "        res.append(np.asarray(xN).T)\n",
    "\n",
    "        # Normalize Ya if unique(Ya) > 10\n",
    "        yN = []\n",
    "        for a in y.T:\n",
    "            if np.unique(a, axis=0).shape[0] > self.dis:\n",
    "                yN.append(self.normalize(a))\n",
    "            else:\n",
    "                yN.append(a)\n",
    "        res.append(np.asarray(yN).T)\n",
    "\n",
    "        # Normalize Za if unique(Za) > 10\n",
    "        zN = []\n",
    "        if np.all(z) != None:\n",
    "            for a in z.T:\n",
    "                if np.unique(a, axis=0).shape[0] > self.dis:\n",
    "                    zN.append(self.normalize(a))\n",
    "                else:\n",
    "                    zN.append(a)\n",
    "            res.append(np.asarray(zN).T)\n",
    "        else:\n",
    "            res.append(None)\n",
    "        return res\n",
    "\n",
    "    def transform_data(self, x, y, z=None):\n",
    "        if self.transform == 'rank':\n",
    "            return self.rank_transform(x, y, z)\n",
    "        elif self.transform == 'standardize':\n",
    "            return self.standard_transform(x, y, z)\n",
    "        elif self.transform == 'normalize':\n",
    "            return self.normal_transform(x, y, z)\n",
    "        elif self.transform == 'uniform':\n",
    "            return self.uniform_transform(x, y, z)\n",
    "        return (x, y, z)\n",
    "\n",
    "    def count_NN(self, tree, points, rho):\n",
    "        '''\n",
    "            Count all nearest neighbors with distance smaller or equal to rho. (Note, this does not include point itself.)\n",
    "        '''\n",
    "        return tree.query_ball_point(points, rho, p=np.inf, return_length=True)-1\n",
    "\n",
    "\n",
    "    def return_NN(self, tree, points, sigma):\n",
    "        '''\n",
    "            Return all nearest neighbors with distance smaller or equal to sigma. (Note, excludes point itself.)\n",
    "        '''\n",
    "        # includes points itself\n",
    "        neighbors = tree.query_ball_point(points, sigma, p=np.inf)\n",
    "        # exclude points withing neighborhood\n",
    "        for i in range(len(points)):\n",
    "            neighbors[i].remove(i)\n",
    "\n",
    "        return neighbors\n",
    "\n",
    "\n",
    "    def compute_mi(self, x, y):\n",
    "        '''\n",
    "            Estimate the mutual information I(X;Y) of X and Y from n samples (x_i, y_i)_{i=1}^n\n",
    "            using Alg. 1 which relates to the *Mixed-KSG* mutual information estimator of Gao et al. (2017)\n",
    "\n",
    "            Note: Using digamma instead of log according to Mesner et al. (2021)\n",
    "\n",
    "            Input:  x: 2D array of size n*dz (or 1D list of size n if dx = 1)\n",
    "                    y: 2D array of size n*dz (or 1D list of size n if dy = 1)\n",
    "                    (self.kcmi: k-nearest neighbor parameter)\n",
    "\n",
    "            Output: ^I_n(X;Y)\n",
    "        '''\n",
    "        assert len(x) == len(y), \"x and y should have the same number of observations\"\n",
    "        n = len(x)\n",
    "        assert self.kcmi <= n-1, \"Set kcmi smaller than number of observations - 1\"\n",
    "\n",
    "        x =  x.reshape((n, 1)).astype(np.float32) if (x.shape == (n,)) else x.astype(np.float32)\n",
    "        y =  y.reshape((n, 1)).astype(np.float32) if (y.shape == (n,)) else y.astype(np.float32)\n",
    "        xy = np.concatenate((x, y), axis=1)\n",
    "\n",
    "        # build k-d trees\n",
    "        tree_xy = KDTree(xy, leafsize=self.leafsize)\n",
    "        tree_x = KDTree(x, leafsize=self.leafsize)\n",
    "        tree_y = KDTree(y, leafsize=self.leafsize)\n",
    "\n",
    "        # compute k-NN distances, using k+1 as this includes dist to self\n",
    "        rho = tree_xy.query(xy, self.kcmi+1, p=np.inf)[0][:, self.kcmi]\n",
    "\n",
    "        # if continous  -> k_tilde = k_cmi\n",
    "        # if discrete or mixed -> k_tilde = number of samples with distance rho\n",
    "        k_tilde = self.count_NN(tree_xy, xy, rho)\n",
    "\n",
    "        # entropy estimates - i.e., count points withon distance rho\n",
    "        nx = self.count_NN(tree_x, x, rho)\n",
    "        ny = self.count_NN(tree_y, y, rho)\n",
    "\n",
    "        mi = np.mean(digamma(k_tilde) + digamma(n) - digamma(nx) - digamma(ny))\n",
    "        return max(0,mi)\n",
    "\n",
    "    def compute_cmi(self, x, y, z):\n",
    "        '''\n",
    "            Estimate the conditional mutual information I(X;Y|Z) of X and Y given a dz-dimensional variable Z from samples (x_i, y_i,z_i)_{i=1}^n\n",
    "            Using Alg. 1 which relates to the *Mixed-KSG* mutual information estimator of Mesner et al. (2021)\n",
    "\n",
    "            Input:  x: 2D array of size n*dz (or 1D list of size n if dx = 1)\n",
    "                    y: 2D array of size n*dz (or 1D list of size n if dy = 1)\n",
    "                    z: 2D array of size n*dz (or 1D list of size n if dz = 1)\n",
    "                    (self.kcmi: k-nearest neighbor parameter)\n",
    "\n",
    "            Output: ^I_n(X;Y|Z)\n",
    "        '''\n",
    "        assert len(x) == len(y) == len(z), \"x, y, and z should have same number of observations\"\n",
    "        n=len(x)\n",
    "        assert self.kcmi <= n-1, \"Set kcmi smaller than number of observations - 1\"\n",
    "\n",
    "        x =  x.reshape((n, 1)).astype(np.float32) if (x.shape == (n,)) else x.astype(np.float32)\n",
    "        y =  y.reshape((n, 1)).astype(np.float32) if (y.shape == (n,)) else y.astype(np.float32)\n",
    "        z =  z.reshape((n, 1)).astype(np.float32) if (z.shape == (n,)) else z.astype(np.float32)\n",
    "\n",
    "        yz = np.concatenate((y, z), axis=1)\n",
    "        xyz = np.concatenate((x, yz), axis=1)\n",
    "        xz = np.concatenate((x, z), axis=1)\n",
    "\n",
    "        # build k-d trees\n",
    "        tree_xyz = KDTree(xyz, leafsize= self.leafsize)\n",
    "        tree_xz = KDTree(xz, leafsize= self.leafsize)\n",
    "        tree_yz = KDTree(yz, leafsize= self.leafsize)\n",
    "        tree_z = KDTree(z, leafsize= self.leafsize)\n",
    "\n",
    "        # compute k-NN distances, using k+1 as this includes dist to self\n",
    "        rho = tree_xyz.query(xyz, self.kcmi+1, p=np.inf)[0][:, self.kcmi]\n",
    "\n",
    "        # if continous  -> k_tilde = k_cmi\n",
    "        # if discrete or mixed -> k_tilde = number of samples with distance rho\n",
    "        k_tilde = self.count_NN(tree_xyz, xyz, rho)\n",
    "\n",
    "        # entropy estimates - i.e., count neighbors within distance rho\n",
    "        nxz = self.count_NN(tree_xz, xz, rho)\n",
    "        nyz = self.count_NN(tree_yz, yz, rho)\n",
    "        nz = self.count_NN(tree_z, z, rho)\n",
    "\n",
    "        cmi = np.mean(digamma(k_tilde) - digamma(nxz) - digamma(nyz) + digamma(nz))\n",
    "        return max(0,cmi)\n",
    "\n",
    "    def compute_pval_mi(self, x, y):\n",
    "        '''\n",
    "            Returns the p value returning p value for H_0: X _||_ Y estimated from n samples (x_i, y_i)_{i=1}^n\n",
    "            using Alg. 2 of Huegle et al. (2022), i.e., comparing the present MI against MIs for shuffled samples of X under H_0.\n",
    "\n",
    "            H_0: X and Y are independent\n",
    "            H_1: X and Y are dependent\n",
    "\n",
    "            Note: Using rank transformation for k-NN searches according to Runge (2017) but preserving ties\n",
    "\n",
    "            Input:  x: 2D array of size n*dz (or 1D list of size n if dx = 1)\n",
    "                    y: 2D array of size n*dz (or 1D list of size n if dy = 1)\n",
    "                    (self.Mperm: number of permutations)\n",
    "                    (self.kcmi: k used for MI estimation)\n",
    "\n",
    "            Output: p_perm,n\n",
    "        '''\n",
    "\n",
    "        assert len(x) == len(y), \"x and y should have same number of observations\"\n",
    "\n",
    "        if self.subsample is not None:\n",
    "            sample = np.random.choice(np.arange(len(x)), min(len(x), self.subsample), replace=False)\n",
    "            x, y = x[sample], y[sample]\n",
    "\n",
    "        n = len(x)\n",
    "\n",
    "        x =  x.reshape((n, 1)).astype(np.float32) if (x.shape == (n,)) else x.astype(np.float32)\n",
    "        y =  y.reshape((n, 1)).astype(np.float32) if (y.shape == (n,)) else y.astype(np.float32)\n",
    "\n",
    "        x, y, _ = self.transform_data(x,y)\n",
    "\n",
    "        n = len(x)\n",
    "        if self.kperm == 0:\n",
    "            self.kperm = np.floor(np.sqrt(n)).astype(int)\n",
    "        elif 0 < self.kperm <= 1:\n",
    "            self.kperm = np.floor(np.nextafter(self.kperm,0) * n).astype(int) # ensure kperm < n (n-1 equals shuffling without considering z)\n",
    "\n",
    "        if self.kcmi == 0:\n",
    "            self.kcmi = np.floor(np.sqrt(n)).astype(int)\n",
    "        elif 0 < self.kcmi <= 1:\n",
    "            self.kcmi = np.floor(np.nextafter(self.kcmi,0) * n).astype(int) # ensure kcmi < n\n",
    "\n",
    "        # estimate present MI value\n",
    "        self.cmi_val = self.compute_mi(x, y)\n",
    "\n",
    "        # estimate Mperm MIs for shuffled X under H_0\n",
    "        null_dist = np.zeros(self.Mperm)\n",
    "        for m in range(self.Mperm):\n",
    "             # Generate random shuffled x\n",
    "            x_shuffled = x[np.random.default_rng().permutation(n)]\n",
    "            null_dist[m] = self.compute_mi(x_shuffled, y)\n",
    "\n",
    "        # estimate pvalue comparing MI against MIs for shuffled X\n",
    "        self.null_distribution = null_dist\n",
    "        self.pval = (1+np.sum(null_dist >= self.cmi_val))/(1+self.Mperm)\n",
    "        return self.pval\n",
    "\n",
    "    def compute_pval(self, x, y, z=None):\n",
    "        '''\n",
    "            Returns the p value returning p value for H_0: X _||_ Y | Z estimated from n samples (x_i, y_i,z_i)_{i=1}^n\n",
    "            using Alg. 2 of Huegle et al. (2022), i.e., comparing the present MI against MIs for shuffled samples of X under H_0.\n",
    "\n",
    "            H_0: X and Y are independent given dz dimensional Z\n",
    "            H_1: X and Y are dependent given dz dimensional Z\n",
    "\n",
    "            Note: Using rank transformation for k-NN searches according to Runge (2017) but preserving ties\n",
    "\n",
    "            Input:  x: 1D 2D array of size n*dz (or 1D list of size n if dx = 1)\n",
    "                    y: 1D 2D array of size n*dz (or 1D list of size n if dy = 1)\n",
    "                    z: 2D array of size n*dz (or 1D list of size n if dz = 1)\n",
    "                    (self.Mperm: number of permutations)\n",
    "                    (self.kperm: k used for local permuation scheme)\n",
    "                    (self.kcmi: k used for MI estimation)\n",
    "\n",
    "            Output: p_perm,n\n",
    "        '''\n",
    "\n",
    "        # for empty z calculate return p value according to H_0: X _||_ Y\n",
    "        if z is None:\n",
    "            return self.compute_pval_mi(x, y)\n",
    "\n",
    "        assert len(x) == len(y) == len(z), \"x, y, and z should have same number of observations\"\n",
    "\n",
    "        if self.subsample is not None:\n",
    "            sample = np.random.choice(np.arange(len(x)), min(len(x), self.subsample), replace=False)\n",
    "            x, y, z = x[sample], y[sample], z[sample]\n",
    "\n",
    "        n = len(x)\n",
    "\n",
    "        x =  x.reshape((n, 1)).astype(np.float32) if (x.shape == (n,)) else x.astype(np.float32)\n",
    "        y =  y.reshape((n, 1)).astype(np.float32) if (y.shape == (n,)) else y.astype(np.float32)\n",
    "        z =  z.reshape((n, 1)).astype(np.float32) if (z.shape == (n,)) else z.astype(np.float32)\n",
    "        x, y, z = self.transform_data(x, y, z)\n",
    "\n",
    "        if self.kperm == 0:\n",
    "            self.kperm = np.floor(np.sqrt(n)).astype(int)\n",
    "        elif 0 < self.kperm <= 1:\n",
    "            self.kperm = np.floor(np.nextafter(self.kperm,0) * n).astype(int) # ensure kperm < n (n-1 equals shuffling without considering z)\n",
    "\n",
    "        if self.kcmi == 0:\n",
    "            self.kcmi = np.floor(np.sqrt(n)).astype(int)\n",
    "        elif 0 < self.kcmi <= 1:\n",
    "            self.kcmi = np.floor(np.nextafter(self.kcmi,0) * n).astype(int) # ensure kcmi < n\n",
    "\n",
    "        # estimate present CMI value\n",
    "        self.cmi_val = self.compute_cmi(x, y, z)\n",
    "\n",
    "        # Get nearest neighbors around each sample point in Z\n",
    "        tree_z = KDTree(z, leafsize= self.leafsize)\n",
    "\n",
    "        # compute k-NN distances in Z, using k+1 as this includes dist to self\n",
    "        sigma = tree_z.query(z, self.kperm+1, p=np.inf)[0][:, self.kperm]\n",
    "\n",
    "        # if continuous -> k points distance smaller or equal to sigma excluding the point itself\n",
    "        # if discrete or mixed -> all points with distance smaller or euqla to the k-NN distance sigma excluding the point itself\n",
    "        neighbors = self.return_NN(tree_z, z, sigma)\n",
    "\n",
    "        # estimate Mperm CMIs for shuffled X under H_0 while preserving marginal distributions\n",
    "        null_dist = np.zeros(self.Mperm)\n",
    "        for m in range(self.Mperm):\n",
    "            # compose local permutations of nearest neighbors to receive a restricted permutation of the whole index list\n",
    "            permutation = np.arange(n)\n",
    "            for i in range(n-1,-1,-1):\n",
    "                permutation[neighbors[i,]]=permutation[np.random.default_rng().permutation(neighbors[i,])]\n",
    "            x_shuffled = x[permutation]\n",
    "            null_dist[m] = self.compute_cmi(x_shuffled, y, z)\n",
    "\n",
    "        self.null_distribution = null_dist\n",
    "        self.pval = (1+np.sum(null_dist >= self.cmi_val))/(1+self.Mperm)\n",
    "        return self.pval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parallel pc alg\n",
    "# A global dictionary storing the variables passed from the initializer.\n",
    "var_dict = {}\n",
    "\n",
    "\n",
    "def _init_worker(data, data_shape, graph, vertices, test, alpha):\n",
    "    # Using a dictionary is not strictly necessary. You can also\n",
    "    # use global variables.\n",
    "    var_dict['data'] = data\n",
    "    var_dict['data_shape'] = data_shape\n",
    "\n",
    "    var_dict['graph'] = graph\n",
    "    var_dict['vertices'] = vertices\n",
    "\n",
    "    var_dict['alpha'] = alpha\n",
    "    var_dict['test'] = test\n",
    "\n",
    "\n",
    "def _test_worker(i, j, lvl):\n",
    "    test = var_dict['test']\n",
    "    alpha = var_dict['alpha']\n",
    "    data_arr = np.frombuffer(var_dict['data']).reshape(var_dict['data_shape'])\n",
    "    graph = np.frombuffer(var_dict['graph'], dtype=\"int32\").reshape((var_dict['vertices'],\n",
    "                                                                     var_dict['vertices']))\n",
    "    \n",
    "    # unconditional\n",
    "    if lvl < 1:\n",
    "        p_val = test.compute_pval(data_arr[:, [i]], data_arr[:, [j]], z=None)\n",
    "        if (p_val > alpha):\n",
    "            return (i, j, p_val, [])\n",
    "    # conditional\n",
    "    else:\n",
    "        candidates_1 = np.arange(var_dict['vertices'])[(graph[i] == 1)]\n",
    "        candidates_1 = np.delete(candidates_1, np.argwhere((candidates_1==i) | (candidates_1==j)))\n",
    "\n",
    "        if (len(candidates_1) < lvl):\n",
    "            return None\n",
    "        \n",
    "        for S in [list(c) for c in combinations(candidates_1, lvl)]:\n",
    "            p_val = test.compute_pval(data_arr[:, [i]], data_arr[:, [j]], z=data_arr[:, list(S)])\n",
    "            if (p_val > alpha):\n",
    "                return (i, j, p_val, list(S))\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def _unid(g, i, j):\n",
    "    return g.has_edge(i, j) and not g.has_edge(j, i)\n",
    "\n",
    "\n",
    "def _bid(g, i, j):\n",
    "    return g.has_edge(i, j) and g.has_edge(j, i)\n",
    "\n",
    "\n",
    "def _adj(g, i, j):\n",
    "    return g.has_edge(i, j) or g.has_edge(j, i)\n",
    "\n",
    "\n",
    "def rule1(g, j, k):\n",
    "    for i in g.predecessors(j):\n",
    "        # i -> j s.t. i not adjacent to k\n",
    "        if _unid(g, i, j) and not _adj(g, i, k):\n",
    "            g.remove_edge(k, j)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def rule2(g, i, j):\n",
    "    for k in g.successors(i):\n",
    "        # i -> k -> j\n",
    "        if _unid(g, k, j) and _unid(g, i, k):\n",
    "            g.remove_edge(j, i)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def rule3(g, i, j):\n",
    "    for k, l in combinations(g.predecessors(j), 2):\n",
    "        # i <-> k -> j and i <-> l -> j s.t. k not adjacent to l\n",
    "        if (not _adj(g, k, l) and _bid(g, i, k) and _bid(g, i, l) and _unid(g, l, j) and _unid(g, k, j)):\n",
    "            g.remove_edge(j, i)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def rule4(g, i, j):\n",
    "    for l in g.predecessors(j):\n",
    "        for k in g.predecessors(l):\n",
    "            # i <-> k -> l -> j s.t. k not adjacent to j and i adjacent to l\n",
    "            if (not _adj(g, k, j) and _adj(g, i, l) and _unid(g, k, l) and _unid(g, l, j) and _bid(g, i, k)):\n",
    "                g.remove_edge(j, i)\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _direct_edges(graph, sepsets):\n",
    "    digraph = nx.DiGraph(graph)\n",
    "    for i in graph.nodes():\n",
    "        for j in nx.non_neighbors(graph, i):\n",
    "            for k in nx.common_neighbors(graph, i, j):\n",
    "                sepset = sepsets[(i, j)] if (i, j) in sepsets else []\n",
    "                if k not in sepset:\n",
    "                    if (k, i) in digraph.edges() and (i, k) in digraph.edges():\n",
    "                        digraph.remove_edge(k, i)\n",
    "                    if (k, j) in digraph.edges() and (j, k) in digraph.edges():\n",
    "                        digraph.remove_edge(k, j)\n",
    "\n",
    "    bidirectional_edges = [(i, j) for i, j in digraph.edges if digraph.has_edge(j, i)]\n",
    "    for i, j in bidirectional_edges:\n",
    "        if _bid(digraph, i, j):\n",
    "            continue\n",
    "        if (rule1(digraph, i, j) or rule2(digraph, i, j) or rule3(digraph, i, j) or rule4(digraph, i, j)):\n",
    "            continue\n",
    "\n",
    "    return digraph\n",
    "\n",
    "\n",
    "def parallel_stable_pc(data, estimator, alpha=0.05, processes=1, max_level=None):\n",
    "    cols = data.columns\n",
    "    cols_map = np.arange(len(cols))\n",
    "\n",
    "    data_raw = RawArray('d', data.shape[0] * data.shape[1])\n",
    "    # Wrap X as an numpy array so we can easily manipulates its data.\n",
    "    data_arr = np.frombuffer(data_raw).reshape(data.shape)\n",
    "    # Copy data to our shared array.\n",
    "    np.copyto(data_arr, data.values)\n",
    "\n",
    "    # same magic as for data\n",
    "    vertices = len(cols)\n",
    "    graph_raw = RawArray('i', np.ones(vertices*vertices).astype(int))\n",
    "    graph = np.frombuffer(graph_raw, dtype=\"int32\").reshape((vertices, vertices))\n",
    "    sepsets = {}\n",
    "\n",
    "    lvls = range((len(cols) - 1) if max_level is None else min(len(cols)-1, max_level+1))\n",
    "    for lvl in lvls:\n",
    "        configs = [(i, j, lvl) for i, j in product(cols_map, cols_map) if i != j and graph[i][j] == 1]\n",
    "\n",
    "        logging.info(f'Starting level {lvl} pool with {len(configs)} remaining edges at {datetime.now()}')\n",
    "        with Pool(processes=processes, initializer=_init_worker,\n",
    "                  initargs=(data_raw, data.shape, graph_raw, vertices, estimator, alpha)) as pool:\n",
    "            result = pool.starmap(_test_worker, configs)\n",
    "\n",
    "        for r in result:\n",
    "            if r is not None:\n",
    "                graph[r[0]][r[1]] = 0\n",
    "                graph[r[1]][r[0]] = 0\n",
    "                sepsets[(r[0], r[1])] = {'p_val': r[2], 'sepset': r[3]}\n",
    "\n",
    "    nx_graph = nx.from_numpy_matrix(graph)\n",
    "    nx_graph.remove_edges_from(nx.selfloop_edges(nx_graph))\n",
    "    nx_digraph = _direct_edges(nx_graph, sepsets)\n",
    "    nx.relabel_nodes(nx_digraph, lambda i: cols[i], copy=False)\n",
    "    sepsets = {(cols[k[0]], cols[k[1]]): {'p_val': v['p_val'], 'sepset': [cols[e] for e in v['sepset']]}\n",
    "               for k, v in sepsets.items()}\n",
    "\n",
    "    return nx_digraph, sepsets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "# set alpha\n",
    "alpha = 0.05\n",
    "# set number of cores\n",
    "processes = 2\n",
    "# set mCMIkNN parameters\n",
    "kcmi = 25\n",
    "kperm = 5\n",
    "Mperm = 100\n",
    "# set maximum level of pcalg (None == infinite)\n",
    "max_level = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0fab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### execution function\n",
    "def ciTesting(filename, counter):\n",
    "    indep_test = mCMIkNN(kcmi=kcmi,kperm=kperm, Mperm=Mperm)\n",
    "    print(counter, 'processing file', filename)\n",
    "    df = pd.read_csv('../data_generation/csl_data_normalized/'+filename)\n",
    "    graph, sepsets = parallel_stable_pc(df, indep_test, alpha=alpha, processes=processes, max_level=max_level)\n",
    "    nx.write_gml(graph,'results_mCMIkNN/'+filename[:-4]+'.gml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parallel computation\n",
    "directory = os.fsencode('../data_generation/csl_data_normalized/')\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    ciTesting(os.fsdecode(filename), i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0b007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
